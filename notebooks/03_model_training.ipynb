{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Model Training\n",
    "\n",
    "Entrenamiento y evaluación del modelo MarketValueNet.\n",
    "\n",
    "Este notebook cubre:\n",
    "- Carga de features procesadas\n",
    "- Creación del modelo y DataLoaders\n",
    "- Entrenamiento con early stopping\n",
    "- Evaluación: métricas, confusion matrix, curvas de entrenamiento\n",
    "- Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from src.model.architecture import MarketValueNet\n",
    "from src.model.dataset import PolymarketDataset, create_dataloaders\n",
    "from src.model.train import train_model\n",
    "from src.model.evaluate import evaluate_model, print_evaluation\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar datos procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "dataset = PolymarketDataset.from_numpy_dir('../data/processed')\n",
    "\n",
    "print(f'Dataset size: {len(dataset)}')\n",
    "print(f'Numerical features shape: {dataset.numerical.shape}')\n",
    "print(f'Text embeddings shape: {dataset.text_emb.shape}')\n",
    "print(f'\\nLabel distribution:')\n",
    "print(f'  Buy (1):    {int(dataset.labels.sum())} ({dataset.labels.mean():.1%})')\n",
    "print(f'  No Buy (0): {len(dataset) - int(dataset.labels.sum())} ({1 - dataset.labels.mean():.1%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataLoaders\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    val_split=0.2,\n",
    "    use_weighted_sampler=True\n",
    ")\n",
    "\n",
    "print(f'Train batches: {len(train_loader)}')\n",
    "print(f'Val batches: {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crear y entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear modelo\n",
    "model = MarketValueNet(\n",
    "    num_numerical_features=dataset.numerical.shape[1],\n",
    "    num_categories=20,\n",
    "    category_embed_dim=8,\n",
    "    text_embed_dim=dataset.text_emb.shape[1],\n",
    "    hidden_dims=[256, 128, 64],\n",
    "    dropout=0.3,\n",
    "    task='classification',\n",
    ")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Model architecture:\\n{model}')\n",
    "print(f'\\nTotal parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar\n",
    "history = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=50,\n",
    "    lr=1e-3,\n",
    "    device=device,\n",
    "    save_dir='../data/models',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Curvas de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0].set_title('Loss por Época')\n",
    "axes[0].set_xlabel('Época')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "if history.get('val_accuracy'):\n",
    "    axes[1].plot(history['val_accuracy'], color='green', linewidth=2)\n",
    "    axes[1].set_title('Accuracy de Validación')\n",
    "    axes[1].set_xlabel('Época')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Curvas de Entrenamiento', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/03_training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar mejor modelo\n",
    "model.load_state_dict(torch.load('../data/models/best_market_model.pt', weights_only=True))\n",
    "\n",
    "# Evaluar en validación\n",
    "results = evaluate_model(model, val_loader, device=device)\n",
    "print_evaluation(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "cm = results['confusion_matrix']\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=['No Buy', 'Buy'])\n",
    "disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/03_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de scores del modelo\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "scores = results['scores']\n",
    "labels_eval = results['labels']\n",
    "\n",
    "ax.hist(scores[labels_eval == 0], bins=50, alpha=0.5, label='No Buy (real)', color='coral', density=True)\n",
    "ax.hist(scores[labels_eval == 1], bins=50, alpha=0.5, label='Buy (real)', color='steelblue', density=True)\n",
    "ax.axvline(x=0.5, color='black', linestyle='--', label='Threshold (0.5)')\n",
    "ax.set_title('Distribución de Scores del Modelo')\n",
    "ax.set_xlabel('Model Score')\n",
    "ax.set_ylabel('Densidad')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/03_score_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(labels_eval, scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, color='steelblue', linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
    "ax.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/03_roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
